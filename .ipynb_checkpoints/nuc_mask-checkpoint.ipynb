{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import morphology, segmentation, measure, color\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note (Important)<br>\n",
    "You will have to take a blank fluorescein image to correct for uneven illumination.<br>\n",
    "So you might need to change the disk size in strel in the second section.<br>\n",
    "Calculate the minimum and maximum nuclear sizes and make changes<br>\n",
    "accordingly in the section devoted to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting some parameters (these need to be adapted ad libitum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_size = 10 # radius of disk in pixels for preprocessing.\n",
    "d_size1 = 18 # radius of disk for smoothening pixels.\n",
    "max_area = 35000\n",
    "min_area = 8000\n",
    "max_roundness = 1.25\n",
    "min_roundness = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cv2.imread('DAPI1.tif', cv2.IMREAD_GRAYSCALE)\n",
    "DAPI = cv2.imread('DAPI1.tif', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonuniform illumination correction. Function saved in home/MatlabCode. Copy of Image Analyst's code. (August 2, 2016)<br>\n",
    "A = BackgroundCorrect(A, BlankImage.tif);         # Take a blank fluorescein image.<br>\n",
    "B = BackgroundCorrect(B, BlankImage.tif);<br>\n",
    "C = BackgroundCorrect(C, BlankImage.tif);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cv2.equalizeHist(A)  # Some local adjustments, to be able to detect the dimmer cells.\n",
    "A = cv2.morphologyEx(A, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (d_size, d_size)))\n",
    "A = cv2.clearBorder(A)  # Eliminating the objects on the borders.\n",
    "# Removing pixels smaller than the given size.\n",
    "A = cv2.wienerFilter(A, (d_size, d_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the problem of oversegmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = morphology.disk(d_size1)\n",
    "Ao = morphology.opening(A, se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ae = morphology.erosion(A, se)\n",
    "Aobr = morphology.reconstruction(Ae, A)\n",
    "Aoc = morphology.closing(Ao, se)\n",
    "Aobrd = morphology.dilation(Aobr, se)\n",
    "Aobrcbr = morphology.reconstruction(Aobrd, Aobr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Aobrcbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it continues as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = A > threshold_otsu(A)  # graythresh was giving black image. Hence put a random value, works nevertheless for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw1 = morphology.remove_small_holes(bw)\n",
    "bw2 = morphology.opening(bw1, morphology.disk(18))  # Morphological opening.\n",
    "bw3 = morphology.remove_small_objects(bw2, min_size=100)  # Removing cells with less than 100 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw3_perim = segmentation.find_boundaries(bw3)\n",
    "overlay = color.label2rgb(bw3_perim, image=A, colors=[(1, 0.3, 0.3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovering Putative nucleus centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = ndimage.maximum_filter(A, size=5)\n",
    "maxs = morphology.closing(maxs, se)\n",
    "maxs = morphology.remove_small_holes(maxs)\n",
    "maxs = morphology.remove_small_objects(maxs, min_size=100)\n",
    "overlay1 = color.label2rgb(bw3_perim | maxs, image=A, colors=[(1, 0.3, 0.3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the image so that the background pixels and the extended maxima pixels are forced to be the only minima in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jc = 255 - A\n",
    "A_mod = ndimage.morphological_reconstruction(Jc, (bw3 | maxs).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watershed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndimage.distance_transform_edt(A_mod)\n",
    "local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)), labels=A)\n",
    "markers = ndimage.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=A_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting cells and removing under- and over-segmented nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = measure.regionprops(labels, intensity_image=DAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for props in regions:\n",
    "    if props.area <= max_area and props.area >= min_area and \\\n",
    "            (props.perimeter) ** 2 / (4 * np.pi * props.area) <= max_roundness and \\\n",
    "            (props.perimeter) ** 2 / (4 * np.pi * props.area) >= min_roundness and \\\n",
    "            (4 * props.area) / (np.pi * (props.major_axis_length) ** 2) <= max_roundness and \\\n",
    "            (4 * props.area) / (np.pi * (props.major_axis_length) ** 2) >= min_roundness:\n",
    "        cm1 = props.label\n",
    "    else:\n",
    "        cm2 = props.label\n",
    "        labels[props.coords[:, 0], props.coords[:, 1]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell counting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = np.max(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlaying the cells detected over the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = labels > 0\n",
    "overlay2 = color.label2rgb(labels, image=A, bg_label=0, colors=[(.5, .8, .3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing Data<br>\n",
    "Assuming intensity.dat is a file to write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Intensity.dat', 'a') as f:\n",
    "    for props in regions:\n",
    "        idx1 = props.mean_intensity\n",
    "        idx2 = props.area\n",
    "        # idx3 = props.mean_intensity\n",
    "        # idx6 = props.mean_intensity\n",
    "        # idx4 = np.mean(ndimage.standard_deviation(C[props.coords[:, 0], props.coords[:, 1]])) * props.area\n",
    "        # idx5 = np.mean(ndimage.entropy(C[props.coords[:, 0], props.coords[:, 1]])) * props.area\n",
    "        # idx7 = np.mean(ndimage.standard_deviation(B[props.coords[:, 0], props.coords[:, 1]])) * props.area\n",
    "        # idx8 = np.mean(ndimage.entropy(B[props.coords[:, 0], props.coords[:, 1]])) * props.area\n",
    "        \n",
    "        DI = idx1 * idx2  # DAPI intensity\n",
    "        # HI = idx3 * props.area  # H2AX intensity\n",
    "        # KI = idx6 * props.area  # Ki67 Intensity\n",
    "        \n",
    "        f.write(f\"{DI}\\n\") #writing DNA intensity/content into a file\n",
    "# DAPI_total, Ki67_total,H2A_Total\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
